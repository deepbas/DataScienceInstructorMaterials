{
  "hash": "0f5a9e11882a5513d9d8d1e26fad3d23",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Class Activity 23\"\nauthor: \"Your name here\"\ndate: \" May 16 2024\"\nformat:\n  html:\n    df_print: paged\n    editor: visual\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  error: true\n---\n\n\n\n\n\n## Group Activity 1\n\nLoad the `mlbench` package to get `PimaIndiansDiabetes2` dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the data - diabetes\ndata(PimaIndiansDiabetes2)\ndb <- PimaIndiansDiabetes2\ndb <- db %>% drop_na() \ndb_raw <- db %>% select(glucose, insulin, diabetes)\n\ndb_split <- initial_split(db_raw, prop = 0.80)\n# Create training data\ndb_train <- db_split %>% training()\n# Create testing data\ndb_test <- db_split %>% testing()\n```\n:::\n\n\n\n### a. *Creating the Recipe:* Construct a recipe for the model by normalizing `glucose` and `insulin` predictors to predict `diabetes` status on the training set, ensuring data scales are comparable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndb_recipe <- recipe(_____________, data = ________) %>%\n  step_scale(all_predictors()) %>%\n  step_center(all_predictors()) %>% \n  prep()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:1:22: unexpected input\n1: db_recipe <- recipe(__\n                         ^\n```\n\n\n:::\n:::\n\n\n\n\n### b. *Model Specification:* Define the KNN model using a flexible `tune()` placeholder for the number of neighbors, specifying a `classification` task.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_spec <- nearest_neighbor(weight_func = \"rectangular\", \n                             engine = \"kknn\",\n                             mode = \"classification\",\n                             neighbors = _______)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:4:43: unexpected input\n3:                              mode = \"classification\",\n4:                              neighbors = __\n                                             ^\n```\n\n\n:::\n:::\n\n\n\n\n### c. *Creating Folds:* Divide the training data into 10 stratified folds based on the diabetes outcome to prepare for cross-validation, ensuring representation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndb_vfold <- vfold_cv(_______, v = _________, strata = ________, repe)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:1:23: unexpected input\n1: db_vfold <- vfold_cv(__\n                          ^\n```\n\n\n:::\n:::\n\n\n\n### d. *Cross-Validation Grid:* Generate a sequence of K values to test with 10-fold cross-validation, evaluating model performance across a range of neighbors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk_vals <- tibble(neighbors = ____________________)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:1:31: unexpected input\n1: k_vals <- tibble(neighbors = __\n                                  ^\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_fit <- workflow() %>%\n  add_recipe(______) %>%\n  add_model(_______) %>%\n  tune_grid(\n    resamples = ______, \n    grid = _____,\n    metrics = metric_set(yardstick::ppv, yardstick::accuracy, sens, spec),\n    control = control_resamples(save_pred = TRUE))\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:2:15: unexpected input\n1: knn_fit <- workflow() %>%\n2:   add_recipe(__\n                 ^\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_metrics <- collect_metrics(_____) \n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:1:32: unexpected input\n1: cv_metrics <- collect_metrics(__\n                                   ^\n```\n\n\n:::\n:::\n\n\n\n\n### e. *Visualization:* Plot the cross-validation results to determine the optimal K value, comparing different performance metrics visually.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal.results <- cv_metrics %>%  mutate(.metric = as.factor(.metric)) %>%\n  select(neighbors, .metric, mean)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'cv_metrics' not found\n```\n\n\n:::\n\n```{.r .cell-code}\nfinal.results %>%\n  ggplot(aes(x = neighbors, y = mean, color = forcats::fct_reorder2(.metric, neighbors, mean))) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  theme_minimal() +\n  scale_color_wsj() + \n  scale_x_continuous(breaks = k_vals[[1]]) +\n  theme(panel.grid.minor.x = element_blank())+\n  labs(color='Metric', y = \"Estimate\", x = \"K\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'final.results' not found\n```\n\n\n:::\n:::\n\n\n\n\n\n## Group Activity 2\n\n\n### a. Data Preparation and Train-Test Split\n\nLoad the `mlbench` package and `tidymodels` framework, select relevant features for predicting `glucose`, and split the data into training and test sets. For this activity, use `mass` and `insulin` as your features.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlbench)\nlibrary(tidymodels)\nlibrary(dplyr)\n\ndata(PimaIndiansDiabetes2)\ndb <- PimaIndiansDiabetes2 %>% \n  drop_na() %>%\n  select()\n\n# Splitting the data\nset.seed(2056)\ndb_split <- initial_split(db, prop = 0.75)\ndb_train <- training(db_split)\ndb_test <- testing(db_split)\n```\n:::\n\n\n\n\n### b. Model Specification\n\nDefine a linear regression model for predicting `glucose` as a function of `mass` and `insulin.`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_spec <- \n\nlm_spec\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'lm_spec' not found\n```\n\n\n:::\n:::\n\n\n\n\n### c. Fit the Model\n\nFit the linear model to the training data, predicting `glucose` based on `mass` and `insulin.`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_mod <- \n  \n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <text>:3:0: unexpected end of input\n1: lm_mod <- \n2:   \n  ^\n```\n\n\n:::\n:::\n\n\n\n\n### d. Predict on Test Data and Evaluate the Model\n\nUse the fitted model to predict `glucose` levels on the test set and evaluate the model's accuracy with RMSE and R-squared metrics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predicting glucose levels\nresults <- db_test %>%\n  bind_cols(predictions = predict(lm_mod, new_data = , type = )) %>%\n  select( )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'lm_mod' not found\n```\n\n\n:::\n\n```{.r .cell-code}\n# Displaying first 6 predictions\nresults %>%\n  slice_head(n = 6) %>%\n  knitr::kable()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'results' not found\n```\n\n\n:::\n\n```{.r .cell-code}\n# Evaluating the model\neval_metrics <- metric_set(rmse, rsq)\n\neval_metrics(data = ,\n             truth = ,\n             estimate = ) %>%\n  select(-2) %>%\n  knitr::kable()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `metric_set()`:\n! Failed to compute `rmse()`.\nCaused by error:\n! argument \"data\" is missing, with no default\n```\n\n\n:::\n:::\n\n\n\n\n### (Bonus) Create a scatter plot to visualize the actual vs. predicted glucose levels, including a regression line for reference.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults %>%\n  ggplot(aes(x = , y = )) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Predicted vs Actual Glucose Levels\",\n       x = \"Actual Glucose\",\n       y = \"Predicted Glucose\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'results' not found\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Class-activity-23_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}