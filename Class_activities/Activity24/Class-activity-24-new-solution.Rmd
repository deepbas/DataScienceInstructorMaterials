---
title: "Class Activity 25"
author: "Your name here"
date: "`r format(Sys.Date(), ' %B %d %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      size = "small", 
                      collapse = TRUE, 
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE,
                      error = TRUE) # change it to TRUE

# load the necessary libraries
library(tidyverse) 
library(ggthemes)
library(janitor)
library(broom)
library(tidymodels)
library(mlbench)
library(probably)

select <- dplyr::select
theme_set(theme_stata(base_size = 10))



data(PimaIndiansDiabetes2)
db <- PimaIndiansDiabetes2
db <- db %>% drop_na() %>% 
  mutate(diabetes = fct_relevel(diabetes, c("neg", "pos"))) # Relevels 'diabetes' factor to ensure 'neg' comes before 'pos'
```


\vspace*{1in}



## Group Activity 1

In this activity, we will calculate the probability of diabetes for a glucose level of 150 mg/dL using the logistic regression coefficients $\beta_0 = -5.61$ and $\beta_1 = 0.0392$.

### a. Calculate Log Odds

First, calculate the log odds for a glucose level of 150 mg/dL.

```{r}
log_odds <- -5.61 + (0.0392 * 150)
log_odds
```


### b. Convert Log Odds to Odds

```{r}
odds <- exp(log_odds)
odds
```


### c. Convert Odds to Probability

Finally, convert the odds to probability.

```{r}
probability <- odds / (1 + odds)
probability
```

The probability of having diabetes at a glucose level of 150 mg/dL is calculated to be `r probability`.

---------------------------------------------------------

## Group Activity 2

a. Let's fit the logistic regression model.

```{r}
set.seed(12345)
db_single <- db %>% select(diabetes, glucose)
db_split <- initial_split(db_single, prop = 0.80)

# Create training data
db_train <- db_split %>% training()

# Create testing data
db_test <- db_split %>% testing()

fitted_logistic_model <- logistic_reg() %>% # Call the model function
        # Set the engine/family of the model
        set_engine("glm") %>%
        # Set the mode
        set_mode("classification") %>%
        # Fit the model
        fit(diabetes~., data = db_train)

tidy(fitted_logistic_model)
```


b. We are interested in predicting the diabetes status of patients depending on the amount of glucose. Verify that the glucose value of 143.11 gives the probability of having diabetes as 1/2.

*Answer:*

$$log\left(\frac{p}{1-p}\right)  = \beta_0 + \beta_1x$$


```{r}
(p <- round(exp(-5.61 + 0.0392* 143.11) / (1 + exp(-5.61 + 0.0392* 143.11)),2))
```


c. What value of glucose is needed to have a probability of diabetes of 0.5?

*Answer:*

```{r}
p <- 0.5
(x <- (log(p/(1-p)) - (-5.61))/0.0392)	
```


d. Make a classifier that classifies the diabetes status of new patients with a threshold of 0.5, i.e, a new patient is classified as negative if the estimated class probability is less than 0.75. Also, create a confusion matrix of the resulting predictions. Evaluate the model based on accuracy, sensitivity, specificity, and ppv.


```{r}
# Prediction Probabilities
library(probably)

pred_prob <- predict(fitted_logistic_model,  new_data = db_test,   type = "prob")

db_results <- db_test %>% bind_cols(pred_prob) %>%
  mutate(.pred_class = make_two_class_pred(.pred_neg, levels(diabetes), threshold = .55)) %>%
  select(diabetes, glucose, contains(".pred"))


db_results %>%  
  conf_mat(diabetes,.pred_class) %>% 
  autoplot(type = "heatmap")

# Evaluating the model
eval_metrics <- metric_set(accuracy, sensitivity, specificity, ppv)

eval_metrics(data = db_results,
             truth = diabetes,
             estimate = .pred_class) %>% select(-2) 

```


e. Evaluate the performance of a diabetes prediction model at different classification thresholds and visualize how various metrics such as accuracy, sensitivity, and PPV change across these thresholds. Use a sequence of threshold values, apply each one to classify test data, calculate the performance metrics for each classification, and then create a line plot to illustrate the results.

```{r}
# Step 1: Generate a sequence of thresholds
thresholds <- seq(0, 1, by = 0.1)

# Step 2: Calculate metrics for each threshold using map
metrics_list <- map_df(thresholds, ~{
  db_results <- db_test %>% 
    bind_cols(pred_prob) %>%
    mutate(.pred_class = make_two_class_pred(.pred_neg, levels(diabetes), threshold = .x)) %>%
    select(diabetes, glucose, contains(".pred"))
  
  metrics <- eval_metrics(data = db_results, truth = diabetes, estimate = .pred_class) %>%
    mutate(threshold = .x) %>%
    select(-2) 
  return(metrics)
})

# Step 3: Plot the metrics across thresholds
ggplot(metrics_list, aes(x = threshold, y = .estimate, color = .metric)) +
  geom_line() +
  labs(title = "Model Performance Metrics Across Thresholds",
       x = "Threshold",
       y = "Metric Value") +
  theme_minimal() +
  scale_color_viridis_d(begin = 0.2, end = 0.8, direction = 1, option = "C")
```




e. Generate a ROC Curve and Determine the Optimal Threshold: Evaluate the performance of your diabetes prediction model by plotting a ROC curve. Use the curve to identify the point that is closest to the top-left corner (maximizing sensitivity and minimizing 1 - specificity), and back-calculate to find the corresponding optimal threshold. This threshold represents the best balance between sensitivity (true positive rate) and specificity (false positive rate). 


```{r}
library(yardstick)

# Predict probabilities on the test set
diabetes_prob <- predict(fitted_logistic_model, db_test, type = "prob")
diabetes_results <- db_test %>% 
  select(diabetes) %>%
  bind_cols(diabetes_prob)

# Generate ROC curve data
roc_data <- roc_curve(diabetes_results, truth = diabetes, .pred_neg)


# Plot the ROC curve
roc_plot <- ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line() +
  geom_abline(linetype = "dashed", color = "gray", slope = 1) +
  theme_minimal() +
  labs(title = "ROC Curve", x = "1 - Specificity (False Positive Rate)", y = "Sensitivity (True Positive Rate)")
roc_plot

# Identify the closest point to the top-left corner
optimal_point <- roc_data %>%
  mutate(distance = sqrt((1 - specificity)^2 + (sensitivity - 1)^2)) %>%
  arrange(distance) %>%
  slice(1)
optimal_point
```



