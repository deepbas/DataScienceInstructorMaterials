---
title: "Midterm II"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    extra_dependencies: ["float"]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, warning = FALSE, 
                      message=FALSE, include=TRUE, 
                      fig.height = 4, 
                      fig.width = 5, 
                      error = TRUE, 
                      fig.pos = "H", out.extra = "")

library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(forcats)
library(stringr)
library(lubridate)
```


### Your name: 

\vspace*{0.5in}


# Questions


## Q1 Logistic Regression

We're interested in estimating the probability of developing hypertension based on systolic blood pressure using logistic regression. The logistic regression model has been trained, and the coefficients are $\beta_0 = -3.78$ for the intercept and $\beta_1 = 0.021$ for systolic blood pressure.

### a. Calculate the odds for a systolic blood pressure of 135 mmHg.  (5 points) 

```{r, eval=TRUE, echo=FALSE, fig.pos = "H"}
log_odds_hypertension <- -3.78 + (0.021 * 135)
odds_hypertension <- exp(log_odds_hypertension)
odds_hypertension
```


### b. Convert the odds in part `a` to the probability of developing hypertension.  (5 points) 


```{r, eval=TRUE, echo=FALSE, fig.pos = "H"}
probability_hypertension <- odds_hypertension / (1 + odds_hypertension)
probability_hypertension
```



## Q2 k-Nearest Neighbor

Consider a binary classification problem where we use a k-Nearest Neighbors (k-NN) algorithm. We have a confusion matrix as above, which shows the classification performance:

```{r, eval=TRUE, echo=FALSE, fig.pos = "H"}
# Confusion Matrix
library(kableExtra)
# Define an updated confusion matrix
confusion_matrix <- matrix(c(65, 15, 25, 95), nrow = 2)
colnames(confusion_matrix) <- c("Predicted Negative", "Predicted Positive")
rownames(confusion_matrix) <- c("Actual Negative", "Actual Positive")

# Display the confusion matrix as a table
knitr::kable(confusion_matrix, "latex", booktabs = TRUE, 
      caption = "Confusion Matrix") %>%
  kable_styling(latex_options = c("striped", "scale_down"))

```


### a. (5 points) 

Given the confusion matrix, calculate the model's precision and recall for the "Positive" class. What does this imply about the model's performance in identifying positive cases?


In terms of the model's performance in identifying positive cases:

The recall is relatively high, suggesting that the model is quite good at identifying most of the positive cases.
The precision is slightly lower than the recall, indicating that when the model predicts a case as positive, there's a 
20.8 % chance it's actually negative.

These metrics imply that while the model is quite sensitive to detecting positive cases, it does sacrifice some accuracy, resulting in some false positives. This trade-off is common in predictive modeling and must be balanced against the costs of false positives and false negatives in the specific application context


### b. (5 points) 

Discuss the influence of the k parameter size on the occurrence of overfitting and underfitting within the k-Nearest Neighbors (k-NN) algorithm. How can adjusting k help in achieving a balance to optimize model performance?


The parameter $k$ in $\mathrm{k}$-Nearest Neighbors ( $\mathrm{k}-\mathrm{NN}$ ) determines the number of nearest neighbors to consider when making a classification decision. The choice of $k$ can significantly affect the algorithm's tendency to overfit or underfit:
- Overfitting: If $k$ is too small, the model becomes highly sensitive to noise in the training data, considering only the closest points. This can lead to overfitting, where the model captures noise and irregularities in the training data and may not generalize well to new, unseen data.
- Underfitting: Conversely, if $k$ is too large, the model becomes overly generalized, which can smooth out the prediction too much and result in underfitting. In this case, the model may not capture sufficient nuances of the data distribution and may perform poorly even on the training data.

Balancing with $k$ :
- To achieve a balance and optimize model performance, $k$ should be set to a value that provides a good generalization capability without capturing noise. This is typically done through crossvalidation, where different values of $k$ are tested, and the one that yields the best performance on a validation set is chosen. The optimal $k$ leads to a model that has good performance metrics on both training and validation datasets, indicating a balance between bias and variance.


## Q3 Miscellaneous: Multiple Choice (5 points each)

### a. In logistic regression, odds are defined as:

A) The ratio of the probability of the event occurring to the probability of it not occurring.
B) A direct measure of probability that an event occurs, identical in interpretation.
C) The logarithmic transformation of probabilities for easier computation.
D) The probability of an event occurring divided by the probability of all other events.



### b. In the context of the k-Nearest Neighbors (k-NN) algorithm, consider how the choice of k impacts the model's bias and variance. Select the correct statement from the options below:

A) Increasing the value of k decreases both bias and variance, leading to a universally better model performance across different datasets.
B) Decreasing the value of k to 1 minimizes the model's variance while maximizing its bias, as the prediction is entirely based on the nearest neighbor.
C) Increasing the value of k generally increases the model's bias but reduces its variance, as the classification decision is based on a larger, more generalized set of neighbors.
D) A very large value of k (approaching the size of the training set) results in a model with low bias and high variance, as it becomes too sensitive to the noise in the training data.




### c. When the K-Means clustering algorithm reaches a point where the assignment of observations to clusters remains constant across successive iterations, it indicates:

A) The algorithm has potentially reached a local minimum, but not necessarily the global optimum.
B) The algorithm has converged, indicating stability in cluster assignment and optimal clustering has been achieved.
C) The algorithm requires re-initialization as it has likely converged to a suboptimal solution.
D) The clustering process is incomplete and requires more iterations for accurate cluster assignment.


### d. The utilization of cross-validation techniques in machine learning models:

A) Exclusively mitigates overfitting by training the model on multiple subsets of the data.
B) Can effectively eliminate the need for a separate test set by using the training data for validation.
C) Helps in mitigating both overfitting and underfitting by validating the model's performance on different subsets of the dataset.
D) Guarantees improvement in model performance on unseen data by optimizing hyperparameters.




### e. In logistic regression, changing the decision threshold (default is 0.5 ) affects the model's sensitivity and specificity. Which of the following statements is true when increasing the decision threshold above 0.5 ?

A) Sensitivity increases while specificity decreases.
B) Both sensitivity and specificity increase.
C) Sensitivity decreases while specificity increases.
D) Both sensitivity and specificity decrease.


\newpage

## Q4 Loops and functions

Consider the following data frame `df_waste` which represents the waste generation (in tonnes) of five types of waste materials: Plastic, Metal, Glass, Paper, and Organic in a city over 12 months in a city.

```{r, echo=FALSE, eval=TRUE}
df_waste <- data.frame(
  month = 1:12,
  plastic = c(150, 120, 130, 200, 210, 180, 190, 220, 250, 260, 270, 280),
  metal = c(100, 110, 120, 130, 140, 150, 130, 120, 110, 115, 125, 135),
  glass = c(200, 190, 180, 170, 160, 150, 160, 170, 180, 185, 190, 195),
  paper = c(90, 85, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140),
  organic = c(300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410)
)
```


```{r, eval=TRUE}
glimpse(df_waste)
```


### a (10 points)

Given `df_waste` write a loop to calculate the monthly average waste generation for each type of material. Your resulting output should be a data frame with each row representing the average waste generation for a month and each column representing a type of material.



```{r, echo=TRUE, eval=TRUE}
# Initialize an empty data frame to store monthly averages
monthly_averages <- data.frame(matrix(ncol = ncol(df_waste)-1, nrow = 1))
names(monthly_averages) <- names(df_waste)[-1]

for (i in 1:(ncol(df_waste)-1)) {
  monthly_averages[1, i] <- mean(df_waste[, i+1])
}

monthly_averages
```



### b (10 points)

Given the dataset `df_waste` representing monthly waste generation (in tonnes) for various materials and the vector `seasons` indicating the corresponding season for each month, calculate the average waste generation for each type of material across the four seasons: Winter, Spring, Summer, and Autumn. The seasons are defined as follows:

- Winter: December, January, February
- Spring: March, April, May
- Summer: June, July, August
- Autumn: September, October, November

The `seasons` vector provided is as follows:

```{r, eval=TRUE}
seasons <- c("Winter", "Winter", "Spring", "Spring", "Spring", "Summer", 
             "Summer", "Summer", "Autumn", "Autumn", "Autumn", "Winter")
```

Use `lapply` or `map` functions from R to compute the average waste generation for each material (`Plastic`, `Metal`, `Glass`, `Paper`, `Organic`) for each `season.` The expected output should be a structured data object (like a `list` or a `data frame`) where each entry or row corresponds to a season, showing the average waste generation for each material during that season.



```{r, echo=TRUE, eval=TRUE, fig.pos = "H"}
df_waste$season <- rep(seasons, each = nrow(df_waste) / length(seasons))


average_waste_by_season <- map_dfr(names(df_waste)[2:6], function(material) {
  df_waste %>%
    group_by(season) %>%
    summarize(Material = material,
              Average = mean(.data[[material]], na.rm = TRUE)) %>%
    ungroup()
})

average_waste_by_season
```


## Q5 String Manipulations

### a. (5 points)

Given a vector of words, write a function named `find_vowel_5_letter_words` that identifies all five-letter words starting and ending with a vowel. The function should return the indices of these words within the original vector. For this problem, assume vowels are "a", "e", "i", "o", and "u", and consider case insensitivity.




```{r, echo=TRUE, eval=TRUE}
find_vowel_5_letter_words <- function(words) {
  pattern <- "^[aeiouAEIOU].{3}[aeiouAEIOU]$"
  matches <- str_detect(words, pattern)
  return(which(matches))
}

find_vowel_5_letter_words(c("Ananya", "Elena", "Aya"))
```


### b. (5 points)

```{r}
comments <- c("Loving the new #season!", "Can't wait for #Friday!")
```

Write a command to remove all instances of # from the `comments` vector.


```{r, echo=TRUE, eval=TRUE}
clean_comments <- str_replace_all(comments, "#", "")
print(clean_comments)
```


### c. (5 points)

```{r}
dates <- c("01012023", "15032024")
```

Write a command to insert dashes (-) into the dates vector to achieve the desired format.


```{r, echo=TRUE, eval=TRUE}
formatted_dates <- str_c(
  str_sub(dates, 1, 2), "-",  
  str_sub(dates, 3, 4), "-",  
  str_sub(dates, 5, 8)        
)
print(formatted_dates)
```


### d. (10 points)


```{r}
info <- "John Doe:john.doe@example.com, Jane Smith:jane.smith@example.com"
```

Use the `stringr` functions to separate the names and email addresses into two vectors, `names` and `emails.`


```{r, echo=TRUE, eval=TRUE}
pairs <- str_split(info, ",\\s*")[[1]]

# Further split each pair into name and email
separated_info <- str_split(pairs, ":")
names <- sapply(separated_info, `[`, 1)
emails <- sapply(separated_info, `[`, 2)

print(names)
print(emails)
```


## Q6 Shiny

There are two bugs in the Shiny app provided below. Find and fix them. What does this Shiny app do? Just need to write a conceptual answer.


```{r, eval=FALSE}
library(shiny)
library(dplyr)
library(babynames)

ui <- fluidPage(
  selectInput("nameInput", "Choose a name", choices = unique(babynames$name)),
  actionButton("submitButton", "Show Details"),
  textOutput("nameDetails")
)

server <- function(input, output, session) {
  observeEvent(input$submitButton, {
    # Fix: Correctly refer to the button's ID as 'submitButton'
    # Fix: Remove isolate to allow the action to trigger the event
    selectedName <- input$nameInput
    details <- babynames %>%
      filter(name == selectedName) %>%
      summarise(Total = sum(n), Proportion = mean(prop))
    
    output$nameDetails <- renderText({
      paste("Total occurrences of", selectedName, ":", details$Total, "\nAverage proportion:", details$Proportion)
    })
  })
}

shinyApp(ui, server)

```



